"""
RAG TabanlÄ± CV Chatbot - OpenAI Versiyonu
Nil YaÄŸmur Muslu'nun CV bilgilerini kullanarak sorulara cevap verir.
"""
#BÃ¶lÃ¼m 1 Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi
#Bu bÃ¶lÃ¼mde projenin Ã§alÄ±ÅŸmasÄ± iÃ§in gereken araÃ§larÄ± Ã§aÄŸÄ±racaÄŸÄ±z.

import os # iÅŸletim sistemi ile alakalÄ± dosya var mÄ± kontrolÃ¼ vb.
import warnings 
warnings.filterwarnings('ignore')  #gereksiz uyarÄ±larÄ± gizlemek iÃ§in

import streamlit as st #web arayÃ¼zÃ¼nÃ¼ oluÅŸturmak iÃ§in kullanÄ±lan kÃ¼tÃ¼phane
from langchain.text_splitter import RecursiveCharacterTextSplitter #metni kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lmek iÃ§in
from langchain_community.vectorstores import FAISS #vektÃ¶r veri tabanÄ± kÃ¼tÃ¼phanesi
try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
except ImportError:
    from langchain.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI #gpt modellerine baÄŸlanmak iÃ§in
import pickle #python nesnelerini diske kaydetmek iÃ§in

#BÃ–LÃœM 2 Streamlift Sayfa KonfigÃ¼rasyonu
#bu bÃ¶lÃ¼m tarayÄ±cÄ±da nasÄ±l gÃ¶zÃ¼keceÄŸini belirliyor.
# ===============================
# Sayfa KonfigÃ¼rasyonu
# ===============================

st.set_page_config(
    page_title="Nil YaÄŸmur Muslu - CV Chatbot",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)
#BÃ–LÃœM 3 SAbit DeÄŸiÅŸkenler
# proje boyunca deÄŸiÅŸmeyecek ayarlarÄ± tek bir yere toplama
# ===============================
# KonfigÃ¼rasyon
# ===============================

DATA_FILE = "data.txt" #cv bilgisi iÃ§erir. RAG iÃ§in kullanÄ±lÄ±r.
FAISS_INDEX_PATH = "./faiss_index.pkl" #oluÅŸturulacak veri tabanÄ±nÄ±n dosya adÄ±
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# OpenAI API Key (sabit olarak ayarlandÄ±)
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
#BÃ–LÃœM 4
# ===============================
# Fonksiyonlar
# ===============================

@st.cache_resource  #bu fonksiyonun sonucunu aklÄ±nda tut tekrar tekrar yazdÄ±rma demek
def load_vector_store():
    """FAISS vector store'u yÃ¼kler veya oluÅŸturur.Bu fonksiyon, FAISS vektÃ¶r veritabanÄ±nÄ± yÃ¼kler.EÄŸer 'faiss_index.pkl' dosyasÄ± diskte varsa, onu yÃ¼kler.
    EÄŸer yoksa, 'data.txt' dosyasÄ±ndan sÄ±fÄ±rdan bir index oluÅŸturur."""
    if os.path.exists(FAISS_INDEX_PATH):
        with open(FAISS_INDEX_PATH, 'rb') as f:
            vectorstore = pickle.load(f)
        return vectorstore
    else:
        # Veriyi yÃ¼kle
        with open(DATA_FILE, 'r', encoding='utf-8') as file:
            text = file.read()
        
        # Chunk'lara bÃ¶l
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500, #her parÃ§a en fazla 500 karakter olsun
            chunk_overlap=100, #parÃ§alar arasÄ± 100 karakter ortak olsun
            separators=["\n### ", "\n\n", "\n", " ", ""]
        )
        chunks = text_splitter.split_text(text)
        
        # Embeddings oluÅŸtur metin parÃ§alarÄ± matematiksel vektÃ¶rlere dÃ¶nÃ¼ÅŸÃ¼r.
        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        
        # FAISS index oluÅŸtur metin parÃ§alarÄ± ve embedding modelini alÄ±p yapar.
        vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)
        
        # gelecekte kullanmak iÃ§in kaydet
        with open(FAISS_INDEX_PATH, 'wb') as f:
            pickle.dump(vectorstore, f)
        
        return vectorstore

def get_response(question: str, vectorstore):
    """KullanÄ±cÄ± sorusuna RAG kullanarak cevap Ã¼retir."""
    try:
        # OpenAI model'ini yapÄ±landÄ±r
        llm = ChatOpenAI(
            api_key=OPENAI_API_KEY,
            model="gpt-3.5-turbo",
            temperature=0.3,
            max_tokens=500
        )
        
        # AlakalÄ± chunk'larÄ± bul
        retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
        relevant_docs = retriever.invoke(question)
        
        # Context oluÅŸtur
        context = "\n\n".join([doc.page_content for doc in relevant_docs])
        
        # Prompt
        prompt = f"""Sen Nil YaÄŸmur Muslu'nun kiÅŸisel CV asistanÄ±sÄ±n. Verilen baÄŸlam bilgilerini kullanarak sorularÄ± yanÄ±tla.

BAÄLAM:
{context}

SORU: {question}

YANITLAMA KURALLARI:
1. Sadece verilen baÄŸlam bilgilerini kullan
2. TÃ¼rkÃ§e olarak yanÄ±tla
3. DoÄŸal ve samimi bir Ã¼slup kullan
4. EÄŸer bilgi baÄŸlamda yoksa, "Bu konuda bilgim yok" de
5. KÄ±sa ve Ã¶z yanÄ±tlar ver

YANIT:"""
        
        # Cevap Ã¼ret
        response = llm.invoke(prompt)
        
        return response.content
    
    except Exception as e:
        return f"âŒ Hata: {str(e)}"

         # BÃ–LÃœM 5 web arayÃ¼zÃ¼nÃ¼ oluÅŸturma
# ===============================
# Ana Uygulama
# ===============================

def main():
    # BaÅŸlÄ±k
    st.title("ğŸ¤– Nil YaÄŸmur Muslu - CV Chatbot")
    st.markdown("### KiÅŸisel Asistan")
    st.markdown("---")
    
    # Ana iÃ§erik
    st.info("ğŸ’¬ **Merhaba!** Ben Nil YaÄŸmur Muslu'nun CV asistanÄ±yÄ±m. Onun hakkÄ±nda merak ettiklerinizi sorabilirsiniz.")
    
    # Vector store'u yÃ¼kle
    try:
        with st.spinner("â³ Vector store yÃ¼kleniyor..."):
            vectorstore = load_vector_store()
        st.success("âœ… Sistem hazÄ±r!")
    except Exception as e:
        st.error(f"âŒ Hata: {e}")
        return
    
    # Chat geÃ§miÅŸi
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Chat geÃ§miÅŸini gÃ¶ster
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # KullanÄ±cÄ± giriÅŸi
    if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Asistan cevabÄ±
        with st.chat_message("assistant"):
            with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                #RAG fonksiyonunu ÅŸu an Ã§aÄŸÄ±rÄ±yoruz
                response = get_response(prompt, vectorstore)
            st.markdown(response)
        
        # Asistan mesajÄ±nÄ± ekle
        st.session_state.messages.append({"role": "assistant", "content": response})
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>ğŸ’» Nil YaÄŸmur Muslu'nun kiÅŸisel CV asistanÄ±</p>
        </div>
        """,
        unsafe_allow_html=True
    )

#eÄŸer bu dosya doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rsa main() fonksiyonunu baÅŸlat der
if __name__ == "__main__":
    main()
